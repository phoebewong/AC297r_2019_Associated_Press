{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Glove Embeddings\n",
    "\n",
    "**Nov 17, 2019**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src import constants\n",
    "from src.models.avg_embeddings_model import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = constants.TRAIN_DIR\n",
    "clean_dir = constants.CLEAN_DIR\n",
    "art_prefix = constants.Text_Prefix\n",
    "img_prefix = constants.Media_Prefix\n",
    "tag_types = ['org', 'place', 'subject','person']\n",
    "article_summary = pd.read_csv(f'{train_dir}/{art_prefix}summary.csv')\n",
    "image_summary =  pd.read_csv(f'{train_dir}/{img_prefix}summary.csv')\n",
    "preview_dir = f'{constants.DATA_DIR}/preview'\n",
    "\n",
    "glove_dir = f'{constants.DATA_DIR}/glove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 50\n",
    "glove_data_file = f'{glove_dir}/glove.6B.{D}d.txt'\n",
    "words = pd.read_table(glove_data_file, sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "words_matrix = words.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(w):\n",
    "    try:\n",
    "        return words.loc[w].values\n",
    "    except:\n",
    "        return np.zeros(D)\n",
    "\n",
    "def find_closest_words(word, n=5):\n",
    "    v = vec(word)\n",
    "    diff = words_matrix - v\n",
    "    delta = np.sum(diff * diff, axis=1)\n",
    "    closest_words = []\n",
    "    for i in range(n):\n",
    "        min_ind = np.argmin(delta)\n",
    "        closest_words.append(words.iloc[min_ind].name)\n",
    "        delta[min_ind] = 500\n",
    "    return closest_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>version</th>\n",
       "      <th>version_created</th>\n",
       "      <th>content_type</th>\n",
       "      <th>language</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>long_lat</th>\n",
       "      <th>title</th>\n",
       "      <th>headline</th>\n",
       "      <th>headline_extended</th>\n",
       "      <th>summary</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5485474faec244b0881838c139b4ef10</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-04-18T22:22:45Z</td>\n",
       "      <td>text</td>\n",
       "      <td>en</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>[-74.00597, 40.71427]</td>\n",
       "      <td>FBN--NFL Schedule</td>\n",
       "      <td>Champion Patriots open vs. Steelers; 5 interna...</td>\n",
       "      <td>The NFL's 100th season will begin with its mos...</td>\n",
       "      <td>The NFL's 100th season will begin with its mos...</td>\n",
       "      <td>NEW YORK (AP) — The NFL's 100th season will be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  version       version_created  \\\n",
       "0  5485474faec244b0881838c139b4ef10        5  2019-04-18T22:22:45Z   \n",
       "\n",
       "  content_type language      city        country               long_lat  \\\n",
       "0         text       en  New York  United States  [-74.00597, 40.71427]   \n",
       "\n",
       "               title                                           headline  \\\n",
       "0  FBN--NFL Schedule  Champion Patriots open vs. Steelers; 5 interna...   \n",
       "\n",
       "                                   headline_extended  \\\n",
       "0  The NFL's 100th season will begin with its mos...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The NFL's 100th season will begin with its mos...   \n",
       "\n",
       "                                           full_text  \n",
       "0  NEW YORK (AP) — The NFL's 100th season will be...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_summary.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_embedding(sentence):\n",
    "    avg_embeddings = np.zeros(D)\n",
    "    num_words = len(sentence.split())\n",
    "    count = 0\n",
    "    missed_words = []\n",
    "    for word in sentence.split():\n",
    "        emb = vec(word)\n",
    "        if np.linalg.norm(emb) > 1e-10:\n",
    "            count += 1\n",
    "        else:\n",
    "            missed_words.append(word)\n",
    "        avg_embeddings += vec(word)\n",
    "    return avg_embeddings/num_words, num_words, count, missed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_embeddings = np.zeros(shape=(len(article_summary), D))\n",
    "# all_missed_words = []\n",
    "# start_time = time.time()\n",
    "# for i in range(len(article_summary)):\n",
    "#     if i % 1000 == 0 and i > 0:\n",
    "#         time_it = time.time() - start_time\n",
    "#         print(f'{i} of {len(article_summary)} in {time_it:.2f}s')\n",
    "#     text = article_summary.iloc[i].headline\n",
    "#     text_prep = preprocessing(text)\n",
    "#     emb, total, count, missed_words = average_embedding(text_prep)\n",
    "#     all_missed_words.append(missed_words)\n",
    "#     all_embeddings[i] = emb/np.linalg.norm(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('train_embeddings.npy', all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings_load = np.load('train_embeddings.npy')\n",
    "norms = 1/np.linalg.norm(all_embeddings_load, axis=1).reshape(-1,1)\n",
    "repeated_norms = np.repeat(norms, D, axis=1)\n",
    "norm_embeddings_load = np.multiply(repeated_norms, all_embeddings_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cruze cruises: GM assembly plant closing, maybe for good\n",
      "\n",
      "The Latest: Last car comes off line at GM assembly plant\n",
      "Land deals, incentives OK'd for new auto plant in Detroit\n",
      "Detroit reaches land deals for new Fiat Chrysler plant plan\n",
      "Work progressing on new Fiat Chrysler plant in Detroit\n",
      "Nissan cuts back on more business at English plant\n"
     ]
    }
   ],
   "source": [
    "random_ind = np.random.randint(0, len(article_summary))\n",
    "random_article = article_summary.iloc[random_ind].headline\n",
    "print(random_article + '\\n')\n",
    "text_prep = preprocessing(random_article)\n",
    "emb, total, count, missed_words = average_embedding(text_prep)\n",
    "emb = emb.reshape(-1,1)/np.linalg.norm(emb)\n",
    "\n",
    "# finding nearest neighbors\n",
    "k = 5\n",
    "scores = np.dot(norm_embeddings_load, emb).flatten()\n",
    "scores[random_ind] = 0\n",
    "top_k = np.argsort(-scores)[:k]\n",
    "\n",
    "for ind in top_k:\n",
    "    print(article_summary.iloc[ind].headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
