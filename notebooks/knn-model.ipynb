{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(1, \"../models/\")\n",
    "from baseline import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "# display image from thumbnails folder given list of ids\n",
    "def show_images(imgids):\n",
    "    for img in imgids:\n",
    "        plt.figure()\n",
    "        try:\n",
    "            img=mpimg.imread('../data/image/'+img+'.jpg')\n",
    "            imgplot = plt.imshow(img)\n",
    "        except:\n",
    "            pass\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity metrics\n",
    "\n",
    "# returns number of exact tag overlap\n",
    "def baseline_score(t0,t1):\n",
    "    return len(set(t0) & set(t1))\n",
    "\n",
    "# returns {exact matches} + eta*{synonym matches}\n",
    "def syn_score(t0, t1, eta=0.5):\n",
    "    score = len(set(t0) & set(t1))\n",
    "    for tag in t0:\n",
    "        for syn in wordnet.synsets(tag):\n",
    "            for name in syn.lemma_names():\n",
    "                if name in t1:\n",
    "                    score += eta\n",
    "    return score\n",
    "\n",
    "# returns sum({exact match}*{tfidf val})\n",
    "def tfidf_score(tfidf_df, t0, test):\n",
    "    ref = tfidf_df.loc[test,:]\n",
    "    score = 0\n",
    "    for t in t0:\n",
    "        for i in test:\n",
    "            if t == i:\n",
    "                score += ref[i]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model \n",
    "class KNN():\n",
    "    # @param k: number of neighbors to return\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "    \n",
    "    # @param train: training set of articles \n",
    "    # @article_to_image: map of images associated with each article\n",
    "    def fit(self, train, article_to_image):\n",
    "        self.train = train\n",
    "        self.article_to_image = article_to_image\n",
    "    \n",
    "    # @param sim: function to return similarity score \n",
    "    # @param test: article to predict in form (id, tags)\n",
    "    # TODO: implement sep functions for text train and image train\n",
    "    def predict(self, sim, test):\n",
    "        test_id, test_tags = test\n",
    "        self.ranks = {}\n",
    "        for train_id, train_tags in tqdm(self.train):\n",
    "            s = sim(train_tags, test_tags)\n",
    "            if len(self.ranks) < self.k:\n",
    "                self.ranks[len(self.ranks)] = (train_id, s)\n",
    "            elif s > min(self.ranks.values(), key=lambda x:x[1])[1]:\n",
    "                key = min(self.ranks.keys(), key=lambda x:self.ranks[x][1])\n",
    "                self.ranks[key] = (train_id, s)\n",
    "        self.ranks = sorted(self.ranks.values(), key = lambda x:x[1], reverse=True)\n",
    "        # map to predicted images\n",
    "        self.pred = []\n",
    "        for train_id, s in self.ranks:\n",
    "            self.pred += self.article_to_image[train_id]\n",
    "        return self.pred\n",
    "    \n",
    "    def score(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [04:18<00:00,  9.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract tag data and format as dictionary\n",
    "\n",
    "data_dir = \"../data/csv_outputs/\"\n",
    "article_feats = {}\n",
    "image_feats = {}\n",
    "tag_ref = {'event':'event_tag',\n",
    "           'org':'org_tag',\n",
    "           'org_industry':'org_industry_tag',\n",
    "           'person':'person_tag',\n",
    "           'person_team':'person_team_tag',\n",
    "           'person_type':'person_type',\n",
    "           'place':'place_tag',\n",
    "           'subject':'subject_tag',\n",
    "           'summary':'headline_extended'\n",
    "          }\n",
    "for csv in tqdm(os.listdir(data_dir)):\n",
    "    if 'ap_category' not in csv: # skip ap category for now\n",
    "        df = pd.read_csv(data_dir+csv)\n",
    "        if 'article' in csv:\n",
    "            feat = csv[8:-4]\n",
    "            g = df.groupby(\"id\")[tag_ref[feat]]\n",
    "            article_feats[feat] = g.apply(lambda x: list(x.astype(str).str.lower()))\n",
    "        elif 'image' in csv:\n",
    "            feat = csv[6:-4]\n",
    "            g = df.groupby(\"id\")[tag_ref[feat]]\n",
    "            image_feats[feat] = g.apply(lambda x: list(x.astype(str).str.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11087it [00:00, 553650.92it/s]\n",
      "30098it [00:00, 519859.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# format accessible image and article corpus\n",
    "# TODO: some ids don't overlap\n",
    "\n",
    "images = []\n",
    "for imgid, tags in tqdm(image_feats['subject'].iteritems()):\n",
    "    images.append({'imgid':imgid, 'tags': tags})\n",
    "\n",
    "# images associated with an article\n",
    "df = pd.read_csv('../data/csv_outputs/image_subject.csv')\n",
    "g = df.groupby(\"article_idx\")['id']\n",
    "article_images = g.apply(list).to_dict()\n",
    "\n",
    "articles = []\n",
    "for articleid, tags in tqdm(article_feats['subject'].iteritems()):\n",
    "    if articleid in article_images.keys():\n",
    "        articles.append((articleid,tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"utah authorities say a man killed after leading police on a chase down a busy street is 37-year-old man from the salt lake city suburb of west valley city. salt lake city police said in a news release monday afternoon that the deceased is harold vincent robinson. authorities wouldn't say if the suspect was killed by police gunfire or due to injuries from his truck crashing into a building.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 7237/7237 [00:00<00:00, 112968.90it/s]\n",
      "C:\\Users\\Dianne\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:522: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# knn example use case\n",
    "# predict for first article\n",
    "\n",
    "test = articles[0]\n",
    "train = articles[1:]\n",
    "\n",
    "# test article\n",
    "print(article_feats['summary'][test[0]])\n",
    "\n",
    "model = KNN(3)\n",
    "model.fit(train, article_images)\n",
    "preds = model.predict(baseline_score, test)\n",
    "show_images(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
